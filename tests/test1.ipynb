{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import context\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from diffusion_models.models import UNet\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.fft import fft2, ifft2, fftshift, ifftshift\n",
    "from torch.distributions import Normal, MultivariateNormal\n",
    "from diffusion_models.mri_forward.undersampling_mask import *\n",
    "from diffusion_models.models import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 1, 28, 28]) torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "train = FashionMNIST(\"data\", train=True, download=True, transform=ToTensor())\n",
    "test = FashionMNIST(\"data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=5000)\n",
    "test_loader = DataLoader(test, batch_size=len(test))\n",
    "\n",
    "sample = next(iter(train_loader))\n",
    "print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liotorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
