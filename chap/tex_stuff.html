<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Abstract &mdash; DiffusionMRI 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=d45e8c67"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Idea Corner" href="../idea_corner.html" />
    <link rel="prev" title="diffusion_models.utils.mp_setup.DDP_Proc_Group" href="../_autosummary/diffusion_models.utils.mp_setup.DDP_Proc_Group.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html">
            
              <img src="../_static/diffMRI_logo.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Homepage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Reference</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="#acknowledgements">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="#the-first-appendix">The First Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="#extended-derivations">Extended Derivations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#forward-process-closed-form">Forward Process Closed-Form</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="#discussion">Discussion</a></li>
<li class="toctree-l1"><a class="reference internal" href="#experiments-and-results">Experiments and Results</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#influence-of-schedules-and-image-size-on-the-forward-diffusion">Influence of Schedules and Image Size on the Forward Diffusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#introduction">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#focus-of-this-work">Focus of this Work</a></li>
<li class="toctree-l2"><a class="reference internal" href="#thesis-organization">Thesis Organization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#materials-and-methods">Materials and Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#latent-variable-models">Latent Variable Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#variational-autoencoders">Variational Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kl-divergence-and-variational-lower-bound">KL Divergence and Variational Lower Bound</a></li>
<li class="toctree-l2"><a class="reference internal" href="#diffusion-denoising-probabilistic-models">Diffusion Denoising Probabilistic Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#forward-diffusion-process">Forward Diffusion Process</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mathematical-description">Mathematical Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="#influence-of-scheduling-functions">Influence of Scheduling Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#reverse-diffusion-process">Reverse Diffusion Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loss-functions">Loss Functions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#image-guided-diffusion">Image Guided Diffusion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#map-estimation-for-inverse-problems">MAP Estimation for Inverse Problems</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ddpms-as-priors">DDPMs as Priors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#classifier-guidance">Classifier Guidance</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gradients-and-closed-forms-of-data-consistency-terms">Gradients and Closed-Forms of Data Consistency Terms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#related-work">Related Work</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ddpms-for-image-synthesis">DDPMs for Image Synthesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#image-guided-diffusion-and-reconstruction">Image-Guided Diffusion and Reconstruction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../idea_corner.html">Idea Corner</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DiffusionMRI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Abstract</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/chap/tex_stuff.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="abstract">
<h1>Abstract<a class="headerlink" href="#abstract" title="Link to this heading"></a></h1>
<p>The abstract gives a concise overview of the work you have done. The
reader shall be able to decide whether the work which has been done is
interesting for him by reading the abstract. Provide a brief account on
the following questions:</p>
<ul class="simple">
<li><p>What is the problem you worked on? (Introduction)</p></li>
<li><p>How did you tackle the problem? (Materials and Methods)</p></li>
<li><p>What were your results and findings? (Results)</p></li>
<li><p>Why are your findings significant? (Conclusion)</p></li>
</ul>
<p>The abstract should approximately cover half of a page, and does
generally not contain citations.</p>
</section>
<section id="acknowledgements">
<h1>Acknowledgements<a class="headerlink" href="#acknowledgements" title="Link to this heading"></a></h1>
</section>
<section id="the-first-appendix">
<h1>The First Appendix<a class="headerlink" href="#the-first-appendix" title="Link to this heading"></a></h1>
<p>In the appendix, list the following material:</p>
<ul class="simple">
<li><p>Data (evaluation tables, graphs etc.)</p></li>
<li><p>Program code</p></li>
<li><p>Further material</p></li>
</ul>
</section>
<section id="extended-derivations">
<h1>Extended Derivations<a class="headerlink" href="#extended-derivations" title="Link to this heading"></a></h1>
<section id="forward-process-closed-form">
<span id="app-forward"></span><h2>Forward Process Closed-Form<a class="headerlink" href="#forward-process-closed-form" title="Link to this heading"></a></h2>
<p>Starting with transition distributions</p>
<div class="math notranslate nohighlight">
\[q(\bm{x}_t|\bm{x}_{t-1}) = \mathcal{N}(\sqrt{1-\beta_t} \bm{x}_{t-1}, \beta_t I)\]</div>
<p>the reparameterization <span class="math notranslate nohighlight">\(\alpha = 1 - \beta\)</span> is introduced</p>
<div class="math notranslate nohighlight">
\[q(\bm{x}_t|\bm{x}_{t-1}) = \mathcal{N}(\sqrt{\alpha_t} \bm{x}_{t-1}, (1-\alpha) I)\]</div>
<p>which can also be formulated as</p>
<div class="math notranslate nohighlight">
\[q(\bm{x}_t|\bm{x}_{t-1}) = \sqrt{\alpha_t}\bm{x}_{t-1} + \sqrt{1-\alpha_t}\mathcal{N}(\bm{0}, \bm{I}).\]</div>
<p>For coherent indexing it is beneficial to switch to notation using
random variables</p>
<div class="math notranslate nohighlight">
\[\bm{x}_{t} = \sqrt{\alpha_t}\bm{x}_{t-1} + \sqrt{1-\alpha_t}\bm{\epsilon_{t-1}}
    \label{eq:forward_randomvar}\]</div>
<p>where <span class="math notranslate nohighlight">\(\bm{\epsilon_{t-1}} \sim \mathcal{N}(\bm{0}, \bm{I})\)</span> and
the earlier <span class="math notranslate nohighlight">\(\bm{x}_t\)</span> can be recursively inserted into the
formula. Recalling that the sum <span class="math notranslate nohighlight">\(Z = X + Y\)</span> of two normally
distributed random variables
<span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu_X, \sigma_Y^2)\)</span> and
<span class="math notranslate nohighlight">\(Y \sim \mathcal{N}(\mu_Y, \sigma_Y^2)\)</span> is again normally
distributed according to
<span class="math notranslate nohighlight">\(Z \sim \mathcal{N}(\mu_X + \mu_Y, \sigma_X^2 + \sigma_Y^2)\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    x_t &amp; = \sqrt{\alpha_t} \left( \sqrt{\alpha_{t-1}} \bm{x}_{t-2} + \sqrt{1-\alpha_{t-1}}\bm{\epsilon}_{t-2} \right) + \sqrt{1-\alpha_{t}} \bm{\epsilon}_{t-1} \\
        &amp; = \sqrt{\alpha_{t}\alpha_{t-1}} \bm{x}_{t-2} + \sqrt{\alpha_{t}(1-\alpha_{t-1})} \bm{\epsilon}_{t-2} + \sqrt{1-\alpha_{t}} \bm{\epsilon}_{t-1}         \\
        &amp; = \sqrt{\alpha_{t}\alpha_{t-1}} \bm{x}_{t-2} + \sqrt{\alpha_{t}(1-\alpha_{t-1}) + (1-\alpha_{t})} \bm{\bar{\epsilon}}_{t-2}\end{aligned}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\bm{\bar{\epsilon}}_{t-2}\)</span> is the sum of the random
variables up to <span class="math notranslate nohighlight">\(t-2\)</span> (again Gaussian). The second term can of
course be simplified to</p>
<div class="math notranslate nohighlight">
\[\bm{x}_t = \sqrt{\alpha_{t}\alpha_{t-1}} \bm{x}_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}} \bm{\bar{\epsilon}}_{t-2}\]</div>
<p>which is exactly the same form as in
Eq. <a class="reference external" href="#eq:forward_randomvar">[eq:forward_randomvar]</a>. Therefore the
final form is</p>
<div class="math notranslate nohighlight">
\[\bm{x}_t = \sqrt{\bar{\alpha}_{t}} \bm{x}_{t-2} + \sqrt{1-\bar{\alpha}_{t}} \bm{\bar{\epsilon}}_{t-2}\]</div>
<p>with <span class="math notranslate nohighlight">\(\bar{\alpha_t} = \prod_{s=1}^{t}\alpha_s\)</span> as before.</p>
</section>
</section>
<section id="conclusion">
<h1>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading"></a></h1>
<p>List the conclusions of your work and give evidence for these. Often,
the discussion and the conclusion sections are fused.</p>
</section>
<section id="discussion">
<h1>Discussion<a class="headerlink" href="#discussion" title="Link to this heading"></a></h1>
<p>The discussion section gives an interpretation of what you have done
<a href="#id1"><span class="problematic" id="id2">:raw-latex:`\cite{day2006wap}`</span></a>:</p>
<ul class="simple">
<li><p><em>What do your results mean?</em> Here you discuss, but you do not
recapitulate results. Describe principles, relationships and
generalizations shown. Also, mention inconsistencies or exceptions
you found.</p></li>
<li><p><em>How do your results relate to other’s work?</em> Show how your work
agrees or disagrees with other’s work. Here you can rely on the
information you presented in the “related work” section.</p></li>
<li><p><em>What are implications and applications of your work?</em> State how your
methods may be applied and what implications might be.</p></li>
</ul>
<p>Make sure that introduction/related work and the discussion section act
as a pair, i.e. “be sure the discussion section answers what the
introduction section asked” <a href="#id3"><span class="problematic" id="id4">:raw-latex:`\cite{day2006wap}`</span></a>.</p>
</section>
<section id="experiments-and-results">
<h1>Experiments and Results<a class="headerlink" href="#experiments-and-results" title="Link to this heading"></a></h1>
<p>Describe the evaluation you did in a way, such that an independent
researcher can repeat it. Cover the following questions:</p>
<ul class="simple">
<li><p><em>What is the experimental setup and methodology?</em> Describe the
setting of the experiments and give all the parameters in detail
which you have used. Give a detailed account of how the experiment
was conducted.</p></li>
<li><p><em>What are your results?</em> In this section, a <em>clear description</em> of
the results is given. If you produced lots of data, include only
representative data here and put all results into the appendix.</p></li>
</ul>
<section id="influence-of-schedules-and-image-size-on-the-forward-diffusion">
<span id="sec-forward-diff-experiments"></span><h2>Influence of Schedules and Image Size on the Forward Diffusion<a class="headerlink" href="#influence-of-schedules-and-image-size-on-the-forward-diffusion" title="Link to this heading"></a></h2>
<p>Ho et al. had derived a closed form solution to the forward process of
DDPMs and Nichol et al. investigated alternative options for the noise
scheduling. <a href="#id5"><span class="problematic" id="id6">:raw-latex:`\autocite{ho2020denoising,nichol2021improved}`</span></a>
They concluded that the important parameters to model are not the
variances <span class="math notranslate nohighlight">\(\beta\)</span> of the transitions, but the variances
<span class="math notranslate nohighlight">\(1-\bar{\alpha}\)</span> of the closed-form forward process, since they
are the ones responsible for the destruction of information.</p>
<p>They decided to go with a squared cosine function, since this would be
close to linear smooth out towards the critical beginning and end points
of the process. In Fig.<a class="reference external" href="#fig:alphadash">5.1</a> you can see how
<span class="math notranslate nohighlight">\(1-\bar{\alpha}\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> behave for both approaches. It
is immediately visible that the variances reach the maximum too early
and flatten out for the linear schedule. This leads to the intuition
that the last few steps are not very useful.</p>
<p>The intution can experimentally confirmed by measuring how closely we
get to isotropic noise when passing samples through the forward process.
For this a batch of 50 times the same image was passed through the
different steps of the process and the covariance matrix was calculated.
As a metric for how close the covariance matrix was to the identity
covariance matrix of pure i.i.d Gaussian noise, the identity matrix was
subtracted and the mean of the absolute value of the matrix calculated.
The results can be seen in Fig. <a class="reference external" href="#fig:noisecloseness">5.2</a> and
confirm the intuition: When using linear scheduling we reach the closest
point to pure noise already after around 600 steps for small images, and
after around 700 for larger images. Cosine scheduling also performs
worse on smaller images than on larger ones, but is still capable
providing value for at least 850 timesteps.</p>
</section>
</section>
<section id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h1>
<p>Give an introduction to the topic you have worked on:</p>
<ul class="simple">
<li><p><em>What is the rationale for your work?</em> Give a sufficient description
of the problem, e.g. with a general description of the problem
setting, narrowing down to the particular problem you have been
working on in your thesis. Allow the reader to understand the problem
setting.</p></li>
<li><p><em>What is the scope of your work?</em> Given the above background, state
briefly the focus of the work, what and how you did.</p></li>
<li><p><em>How is your thesis organized?</em> It helps the reader to pick the
interesting points by providing a small text or graph which outlines
the organization of the thesis. The structure given in this document
shows how the general structuring shall look like. However, you may
fuse chapters or change their names according to the requirements of
your thesis.</p></li>
</ul>
<section id="focus-of-this-work">
<h2>Focus of this Work<a class="headerlink" href="#focus-of-this-work" title="Link to this heading"></a></h2>
</section>
<section id="thesis-organization">
<h2>Thesis Organization<a class="headerlink" href="#thesis-organization" title="Link to this heading"></a></h2>
</section>
</section>
<section id="materials-and-methods">
<h1>Materials and Methods<a class="headerlink" href="#materials-and-methods" title="Link to this heading"></a></h1>
<p>The objectives of the “Materials and Methods” section are the following:</p>
<ul class="simple">
<li><p><em>What are tools and methods you used?</em> Introduce the environment, in
which your work has taken place - this can be a software package, a
device or a system description. Make sure sufficiently detailed
descriptions of the algorithms and concepts (e.g. math) you used
shall be placed here.</p></li>
<li><p><em>What is your work?</em> Describe (perhaps in a separate chapter) the key
component of your work, e.g. an algorithm or software framework you
have developed.</p></li>
</ul>
<section id="latent-variable-models">
<h2>Latent Variable Models<a class="headerlink" href="#latent-variable-models" title="Link to this heading"></a></h2>
<p>Before getting started it is important to define the terms used in the
next sections, since they all stem from Bayesian statistics. The
Bayesian theorem can be written as</p>
<div class="math notranslate nohighlight">
\[p(z|x) = \frac{p(x|z)p(z)}{p(x)}\]</div>
<p>where it is implicitly assumed that <span class="math notranslate nohighlight">\(p\)</span> is a probability density
function over two continuous random variables <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(z\)</span>.
The formula holds in general, but in generative modeling and machine
learning it is usually assumed that the letter <span class="math notranslate nohighlight">\(z\)</span> represents a
random variable in a latent (unobserved) space from which – after
successful training – new data can be generated by sampling. This
requires that <span class="math notranslate nohighlight">\(p(z)\)</span> is a simple distribution from which sampling
is easy and that the trained model is capable of mapping values from the
latent distribution to the true data distribution.</p>
<p>Using above described ordering, the four terms in this formula use
distinct names:</p>
<dl class="simple">
<dt><span class="math notranslate nohighlight">\(p(x)\)</span></dt><dd><p>is called the <em>evidence</em> or the <em>marginal likelihood</em>. It encompasses
the actual observations of the data.</p>
</dd>
<dt><span class="math notranslate nohighlight">\(p(z)\)</span></dt><dd><p>is called the <em>prior</em>, since it exposes information on <span class="math notranslate nohighlight">\(z\)</span>
before any conditioning.</p>
</dd>
<dt><span class="math notranslate nohighlight">\(p(z|x)\)</span></dt><dd><p>is called the <em>posterior</em>. It describes the distribution over
<span class="math notranslate nohighlight">\(z\)</span> after (<em>post</em>) having seen the evidence <span class="math notranslate nohighlight">\(x\)</span>.</p>
</dd>
<dt><span class="math notranslate nohighlight">\(p(x|z)\)</span></dt><dd><p>is called the <em>likelihood</em>. It gives the literal likelihood of
observing an example <span class="math notranslate nohighlight">\(x\)</span> when choosing the latent space to be a
specific <span class="math notranslate nohighlight">\(z\)</span>.</p>
</dd>
</dl>
</section>
<section id="variational-autoencoders">
<h2>Variational Autoencoders<a class="headerlink" href="#variational-autoencoders" title="Link to this heading"></a></h2>
<p>One of the most straightforward examples of a generative model, where
the goal is to find such a latent space representation of the training
sample distribution, is the Variational Autoencoder
(VAE) <a href="#id7"><span class="problematic" id="id8">:raw-latex:`\autocite{kingma2022autoencoding}`</span></a>. The name of the
VAE stems from the Autoencoder, a network that tries to recreate its
output through a bottleneck and thereby learns a compressed
representation of the
data. <a href="#id9"><span class="problematic" id="id10">:raw-latex:`\autocite{https://doi.org/10.1002/aic.690370209}`</span></a>
Autoencoders bear similarity to other dimension reduction methods like
Principal Component Analysis (PCA) and therefore were first published
under the name <em>Nonlinear principal component analysis</em>. The
<em>variational</em> part in the VAE stems from the fact that it does not only
learn to recreate input samples through dimensionality reduction, but is
also optimized to represent the distribution over the training samples
as a combination of a parameterized latent distribution
<span class="math notranslate nohighlight">\(p_{\theta_z}(z)\)</span> and a neural network mapping
<span class="math notranslate nohighlight">\(p_{\theta_{NN}}(x|z)\)</span> between the latent space and the sample
space, termed decoder. The latent distribution is chosen such that
sampling from it is easy (e.g. a multivariate Gaussian, with the
parameters being vectors of means and variances). With sufficient
dimensionality reduction the encoding should not overfit and the latent
space should be a good approximation of the true data manifold. This
enables the creation of data, by sampling the latent space and mapping
it to the output.</p>
<p>Marginalizing <span class="math notranslate nohighlight">\(p_\theta(x)\)</span> requires another approximation of the
posterior <span class="math notranslate nohighlight">\(p(z|x)\)</span> with a neural network, termed the encoder
<span class="math notranslate nohighlight">\(p_{\theta_{NN_{in}}}(z|x)\)</span>.</p>
<div class="math notranslate nohighlight">
\[p_{\theta}(x) = \int p_{\theta_{NN}}(x|z) p_{\theta_z}(z) dz = \frac{p_{\theta_{NN_{out}}}(x|z) p_{\theta_z}(z)}{p_{\theta_{NN_{in}}}(z|x)}\]</div>
<p>A schematic of a VAE, separated into these 3 factors – encoder, latent
distribution and decoder – is shown in Fig. <a class="reference external" href="#fig:vae">7.1</a>.</p>
</section>
<section id="kl-divergence-and-variational-lower-bound">
<h2>KL Divergence and Variational Lower Bound<a class="headerlink" href="#kl-divergence-and-variational-lower-bound" title="Link to this heading"></a></h2>
<p>In VAEs, the encoder <span class="math notranslate nohighlight">\(p_{\theta}(z|x)\)</span> needs to approximate the
posterior <span class="math notranslate nohighlight">\(p(z|x)\)</span>, therefore a differentiable loss function is
needed that compares two probability distributions. One such heavily
used measure is the KL (Kullback-Leibler) divergence</p>
<div class="math notranslate nohighlight">
\[KL\left[p_{\theta}(z|x) || p(z|x)\right] = \int \log \frac{p_{\theta}(z|x)}{p(z|x)} p_{\theta}(z|x) dz\]</div>
<p>which has the properties of being strictly non-negative and is only 0 if
the two distributions are equal.</p>
<p>At the same time, the output of the VAE should fit the true data
distribution well, e.g. should maximize the log-likelihood of the
evidence <span class="math notranslate nohighlight">\(p_{\theta}(x|z)\)</span>. This term is mainly responsible for
the reconstruction of truthful samples from the latent space. Combining
the two terms and inverting the signs (for minimization rather than
maximization) gives a loss function known as ELBO (evidence lower bound)
or VLB (variational lower bound).</p>
<div class="math notranslate nohighlight">
\[\label{eq:elbo}
    \mathcal{L}_{VLB} = - \log p_{\theta}(x|z) + KL\left[p_{\theta}(z|x) || p(z|x)\right]\]</div>
</section>
<section id="diffusion-denoising-probabilistic-models">
<h2>Diffusion Denoising Probabilistic Models<a class="headerlink" href="#diffusion-denoising-probabilistic-models" title="Link to this heading"></a></h2>
<p>Diffusion Denoising Probabilistic Models (DDPMs or Diffusion Models) are
a generative model that learn the distribution of images in a training
set. During training, sample images are gradually destroyed by adding
noise over many iterations and a neural network is trained, such that
these steps can be inverted.</p>
<p>As the name suggests, image content is diffused in timesteps, therefore
we use the random variable <span class="math notranslate nohighlight">\(\bm{x}_0\)</span> to represent our original
training images, <span class="math notranslate nohighlight">\(\bm{x}_t\)</span> for (partially noisy) images at an
intermediate timestep and <span class="math notranslate nohighlight">\(\bm{x}_T\)</span> for images at the end of the
process where all information has been destroyed and the distribution
<span class="math notranslate nohighlight">\(q(\bm{x}_T)\)</span> largely follows an isotropic Gaussian distribution.</p>
<p>The goal is to train a network that creates a less noisy image
<span class="math notranslate nohighlight">\(\bm{x}_{t-1}\)</span> from <span class="math notranslate nohighlight">\(\bm{x}_t\)</span>. If this is achieved we
should be able to sample some new <span class="math notranslate nohighlight">\(\bm{x}_T\)</span> and generate new
samples from the training distribution <span class="math notranslate nohighlight">\(q(\bm{x}_0)\)</span> by passing
this noisy image many times through the network until the noise is fully
removed.</p>
<section id="forward-diffusion-process">
<h3>Forward Diffusion Process<a class="headerlink" href="#forward-diffusion-process" title="Link to this heading"></a></h3>
<section id="mathematical-description">
<h4>Mathematical Description<a class="headerlink" href="#mathematical-description" title="Link to this heading"></a></h4>
<p>In order to derive a training objective it is important to understand
the workings of the <em>forward diffusion process</em>. During this process,
i.i.d (independent and identically distributed) Gaussian noise is
applied to the image over many discrete timesteps. A <em>variance schedule</em>
defines the means and variances (<span class="math notranslate nohighlight">\(\sqrt{1-\beta}\)</span> and
<span class="math notranslate nohighlight">\(\beta\)</span>) of the added noise at every
timestep. <a href="#id11"><span class="problematic" id="id12">:raw-latex:`\autocite{ho2020denoising}`</span></a> The whole process can
be expressed as a Markov chain (depicted in
Fig. <a class="reference external" href="#fig:forward_diffusion">7.2</a>), with the factorization</p>
<div class="math notranslate nohighlight">
\[\label{eq:forwardprocess}
    q(\bm{x}_T|\bm{x}_0) = q(\bm{x}_0) \prod_{t=1}^{T} q(\bm{x}_{t}|\bm{x}_{t-1})\]</div>
<p>where the transition distributions
<span class="math notranslate nohighlight">\(q(\bm{x}_t|\bm{x}_{t-1}) = \mathcal{N}(\sqrt{1-\beta_t} \bm{x}_{t-1}, \beta_t I)\)</span>.
An example of iterative destruction of an image by this process is shown
in Fig. <a class="reference external" href="#fig:forward_naoshima">7.3</a>.</p>
<p>Gladly it is not necessary to sample noise again and again in order to
arrive at <span class="math notranslate nohighlight">\(\bm{x}_t\)</span>, since Ho et al. derived a closed-form
solution to the sampling
procedure. <a href="#id13"><span class="problematic" id="id14">:raw-latex:`\autocite{ho2020denoising}`</span></a> For this, the
variance schedule is first reparameterized as <span class="math notranslate nohighlight">\(1-\beta = \alpha\)</span></p>
<div class="math notranslate nohighlight">
\[q(\bm{x}_t | \bm{x}_{t-1}) = \mathcal{N}(\sqrt{\alpha_t} \bm{x}_{t-1}, (1-\alpha_t) \bm{I})
    \label{eq:forward_alpha}\]</div>
<p>and the closed-form solution for <span class="math notranslate nohighlight">\(q(\bm{x}_t|\bm{x}_0)\)</span> is derived
by introducing the cumulative product
<span class="math notranslate nohighlight">\(\bar{\alpha_t} = \prod_{s=1}^{t}\alpha_s\)</span> as</p>
<div class="math notranslate nohighlight">
\[q(\bm{x}_t|\bm{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha_t}}\bm{x}_0, (1-\bar{\alpha_t})\bm{I})
    \label{eq:forward_alphadash}\]</div>
<p>A choice of <span class="math notranslate nohighlight">\(\bar{\alpha_t} \in [0,1]\)</span> in above parameterizaiton
ensures that the variance does not explode in the process, but that the
SNR (signal-to-noise-ratio) still goes to 0 by gradually attenuating the
means, corresponding to the original image. Thanks to the
reparameterization with <span class="math notranslate nohighlight">\(\bar{\alpha_t}\)</span>, the forward process is
also not restricted anymore to discrete timesteps, but a continuous
schedule can be
used. <a href="#id15"><span class="problematic" id="id16">:raw-latex:`\autocite{kingma2023variational,song2021scorebased}`</span></a></p>
<p>The derivation that leads from
Eq. <a class="reference external" href="#eq:forward_alpha">[eq:forward_alpha]</a> to
Eq. <a class="reference external" href="#eq:forward_alphadash">[eq:forward_alphadash]</a> is left to
appendix <a class="reference external" href="#app:forward">2.1</a>.</p>
</section>
<section id="influence-of-scheduling-functions">
<h4>Influence of Scheduling Functions<a class="headerlink" href="#influence-of-scheduling-functions" title="Link to this heading"></a></h4>
<p>The process of information destruction is dependent on the chosen
variance schedule, the number of steps and the image size. Beyond the
most simple case – a constant variance over time – Ho et al. opted for
the second most simple option, a linear schedule, where the variance
<span class="math notranslate nohighlight">\(\beta_t\)</span> grows linearly in
<span class="math notranslate nohighlight">\(t\)</span>. <a href="#id17"><span class="problematic" id="id18">:raw-latex:`\autocite{ho2020denoising}`</span></a> Nichol et al. later
found that a cosine-based schedule gives better results on lower
resolution images, since it does not destruct information quite as
quickly, making it more informative in the last few timesteps. They also
mention that their cosine schedule is purely based on intuition and they
similar functions to perform equally
well. <a href="#id19"><span class="problematic" id="id20">:raw-latex:`\autocite{nichol2021improved}`</span></a> Own experiments
exploring above mentioned parameters are explained
in <a class="reference external" href="#sec:forward_diff_experiments">5.1</a> and plots of the two
different variance schedules are visible in
Fig. <a class="reference external" href="#fig:alphadash">5.1</a>.</p>
</section>
</section>
<section id="reverse-diffusion-process">
<h3>Reverse Diffusion Process<a class="headerlink" href="#reverse-diffusion-process" title="Link to this heading"></a></h3>
<p>DDPMs can be viewed as latent space models in a similar way that
Generative Adversarial Nets or Variational Autoencoders
can. <a href="#id21"><span class="problematic" id="id22">:raw-latex:`\autocite{goodfellow2014generative,kingma2022autoencoding}`</span></a></p>
<p>In DDPMs the reverse process is again a Markov chain and can therefore
again be factorized as</p>
<div class="math notranslate nohighlight">
\[\label{eq:reverseprocess}
    q(\bm{x}_0|\bm{x}_T) = q(\bm{x}_T) \prod_{t=T}^{1} q(\bm{x}_{t-1}|\bm{x}_{t})\]</div>
<p>which means that our network does not learn to approximate the full
inversion, but rather just the transition probabilities
<span class="math notranslate nohighlight">\(q(\bm{x}_{t-1}|\bm{x}_{t})\)</span> in the chain, which are transitions
between several intermediate latent distributions. Sohl-Dickstein et al.
further showed that the reverse transitions are also Gaussian in the
limit of <span class="math notranslate nohighlight">\(t \rightarrow 0\)</span>, e.g. as long as the diffusion steps
are small enough. We therefore approximate</p>
<div class="math notranslate nohighlight">
\[\label{eq:reverseapprox}
    q(\bm{x}_{t-1} | \bm{x}_t) \approx p_{\theta}(\bm{x}_{t-1} | \bm{x}_t) = \mathcal{N}(\bm{\mu}_{\theta}(\bm{x}_t, t),\bm{\Sigma}_{\theta}(\bm{x}_t, t)).\]</div>
</section>
<section id="loss-functions">
<h3>Loss Functions<a class="headerlink" href="#loss-functions" title="Link to this heading"></a></h3>
<p>The combination of forward <span class="math notranslate nohighlight">\(q(\bm{x}_T|\bm{x}_0)\)</span> and reverse
process <span class="math notranslate nohighlight">\(q(\bm{x}_0|\bm{x}_T)\)</span> can be viewed as a chain of many
VAEs and we can again formulate a variational lower bound objective
(Eq. <a class="reference external" href="#eq:elbo">[eq:elbo]</a>) that maximizes log-likelihood of the
output and matches transition
probabilities. <a href="#id23"><span class="problematic" id="id24">:raw-latex:`\autocite{nichol2021improved}`</span></a></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \mathcal{L}_0       &amp; = - \log p_{\theta}(x_0|x_1)                                    \\
    \mathcal{L}_{1:T-1} &amp; = KL\left[q(x_{t-1}|x_t, x_0) || p_{\theta}(x_{t-1}|x_t)\right] \\
    \mathcal{L}_T       &amp; = KL\left[q(x_T|x_0) || p(x_T)\right]\end{aligned}\end{split}\]</div>
<p>The exact posterior <span class="math notranslate nohighlight">\(q(x_{t-1}|x_t, x_0)\)</span> is tractable for
specific samples of the training distribution, therefore
<span class="math notranslate nohighlight">\(\mathcal{L}_{1:T-1}\)</span> could be calculated, since KL divergence has
a closed form solution for two Gaussian distributions.
<span class="math notranslate nohighlight">\(\mathcal{L}_T\)</span> is independent of <span class="math notranslate nohighlight">\(\theta\)</span> and therefore not
used for optimization. It should anyway be very close to zero if the
parameterization of the forward process is correct and forward diffused
samples get close to <span class="math notranslate nohighlight">\(\mathcal{N}(0,\bm{I})\)</span>. The first term is
only used for performance evaluation in terms of log-likelihood, but not
in optimization.</p>
<p>Another simplification is usually taken and
<span class="math notranslate nohighlight">\(p_{\theta}(\bm{x}_{t-1} | \bm{x}_t)\)</span> only approximates the means
<span class="math notranslate nohighlight">\(\bm{\mu}_{\theta}\)</span> and not the variances. For small enough
timesteps, the means determine the transitional distributions much
stronger than the variances. The network is furhter usually trained to
not predict the means directly, but the noise and the means are then
determined through a
reparameterization. <a href="#id25"><span class="problematic" id="id26">:raw-latex:`\autocite{ho2020denoising,nichol2021improved}`</span></a></p>
</section>
</section>
<section id="image-guided-diffusion">
<h2>Image Guided Diffusion<a class="headerlink" href="#image-guided-diffusion" title="Link to this heading"></a></h2>
<p>Both, Choi et al. and Lugmayr et al. make use of unconditional DDPMs for
image-guided diffusion for the tasks of image translation in the former
and in-painting in the
latter. <a href="#id27"><span class="problematic" id="id28">:raw-latex:`\autocite{choi2021ilvr,lugmayr2022repaint}`</span></a>
Similarly, classifier guidance or CLIP-guidance can be used on
unconditional and conditional DDPMs to produce samples of a specific
class or matching a prompt in the unconditional case or to further trade
off sample variability for sample
fidelity. <a href="#id29"><span class="problematic" id="id30">:raw-latex:`\autocite{dhariwal2021diffusion}`</span></a> We show here
that both approaches can be interpreted as special cases of MAP (maximum
a posteriori) estimation and that they can be generalized to other means
of guidance during the reverse process.</p>
<section id="map-estimation-for-inverse-problems">
<h3>MAP Estimation for Inverse Problems<a class="headerlink" href="#map-estimation-for-inverse-problems" title="Link to this heading"></a></h3>
<p>MAP estimation is a statistical concept that is often used for
optimizing the parameters <span class="math notranslate nohighlight">\(\theta\)</span> of a parameterized distribution
to observed data <span class="math notranslate nohighlight">\(z\sim p(z)\)</span> following Bayes rule</p>
<div class="math notranslate nohighlight">
\[\hat{\theta}_{MAP} = \argmax_{\theta} p(\theta | z) = \argmax_{\theta}\frac{p(z|\theta)p(\theta)}{p(z)}\]</div>
<p>or for inverse problems</p>
<div class="math notranslate nohighlight">
\[\hat{x}_{MAP} = \argmax_x p(x|s) = \argmax_x \frac{p(s|x)p(x)}{p(s)}\]</div>
<p>where <span class="math notranslate nohighlight">\(s \sim p(s)\)</span> is the evidence that is provided by the
measured signal, <span class="math notranslate nohighlight">\(p(x)\)</span> is a prior on the desired reconstruction
and the likelihood term <span class="math notranslate nohighlight">\(p(s|x)\)</span> enforces a data consistency
between the measured signal and the true distribution, usually a forward
model of the data-corrupting process. Since maximizing <span class="math notranslate nohighlight">\(p(x|s)\)</span> is
the same as maximizing <span class="math notranslate nohighlight">\(\log(x|s)\)</span> and <span class="math notranslate nohighlight">\(p(s)\)</span> is independent
of <span class="math notranslate nohighlight">\(\theta\)</span>, we can separate the product into a sum.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \hat{x}_{MAP} = \argmax_x log p(x|s) &amp; = \argmax_x \log{\frac{p(s|x)p(x)}{p(s)}} \\
                                         &amp; = \argmax_x \log p(s|x)p(x)               \\
                                         &amp; = \argmax_x \log f(x, s)\end{aligned}\end{split}\]</div>
<p>Such problems are usually optimized using iterative optimization schemes
such as gradient ascent
<span class="math notranslate nohighlight">\(x_{t+1} = x_{t} + \lambda \nabla_{x} f(x, s)\)</span>, with
<span class="math notranslate nohighlight">\(\lambda\)</span> being the step length. It is usually helpful to separate
the data consistency term (likelihood) and regularizer (prior) into
individual terms for joint optimization with their respective gradients
and weights.</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
    \label{eq:mapestimation}
    x_{i+1} = x_{i} + \lambda_1 \nabla_{x_i} \log p(s|x_i) + \lambda_2 \nabla_{x_i} \log p(x_i)\end{aligned}\]</div>
</section>
<section id="ddpms-as-priors">
<h3>DDPMs as Priors<a class="headerlink" href="#ddpms-as-priors" title="Link to this heading"></a></h3>
<p>DDPMs approximate a data distribution over training images <span class="math notranslate nohighlight">\(p(x)\)</span>
and according to Song et al., they do so by learning to approximate
gradients of the distribution and taking a gradient ascent step with
every iteration of the reverse diffusion
process. <a href="#id31"><span class="problematic" id="id32">:raw-latex:`\autocite{song2020generative}`</span></a> With this
interpretation the DDPM has the exact same form as
Eq. <a class="reference external" href="#eq:mapestimation">[eq:mapestimation]</a> without the data
consistency term <span class="math notranslate nohighlight">\(p(s|x)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\label{eq:ddpmiteration}
    x_{t-1} = x_{t} + \nabla_{x_t} \log p(x_t)\]</div>
</section>
<section id="classifier-guidance">
<h3>Classifier Guidance<a class="headerlink" href="#classifier-guidance" title="Link to this heading"></a></h3>
<p>Classifier guidance as termed by Nichol et al. introduces a data
consistency term <span class="math notranslate nohighlight">\(p(s|x_t)\)</span> in the form of a classifier trained on
noisy images, where <span class="math notranslate nohighlight">\(s\)</span> is the random variable expressing if an
image belongs to a certain
class. <a href="#id33"><span class="problematic" id="id34">:raw-latex:`\autocite{dhariwal2021diffusion,sohldickstein2015deep}`</span></a>
Conditioning on a classifier is sucessfully used by taking gradient
ascent steps not only in the direction that maximizes the prior
<span class="math notranslate nohighlight">\(p(x)\)</span> in a DDPM <span class="math notranslate nohighlight">\(\nabla_{x_t} \log p(x_t)\)</span>, but also the
direction of this conditioning term <span class="math notranslate nohighlight">\(\nabla_{x_t} \log p(s|x_t)\)</span>.
In total, this is equal to
Eq. <a class="reference external" href="#eq:mapestimation">[eq:mapestimation]</a></p>
<div class="math notranslate nohighlight">
\[x_{t+1} = \underbrace{x_{t} + \nabla_{x_t} \log p(x_t)}_{x'_{t+1}} + \lambda \nabla_{x_t} \log p(s|x_t)\]</div>
<p>with <span class="math notranslate nohighlight">\(x'_{t+1}\)</span> being the prediction of the reverse diffusion
steps before any conditioning and <span class="math notranslate nohighlight">\(\lambda\)</span> an arbitrary factor
determining the strength of the guidance.</p>
</section>
<section id="gradients-and-closed-forms-of-data-consistency-terms">
<h3>Gradients and Closed-Forms of Data Consistency Terms<a class="headerlink" href="#gradients-and-closed-forms-of-data-consistency-terms" title="Link to this heading"></a></h3>
<p>Starting from Eq. <a class="reference external" href="#eq:ddpmiteration">[eq:ddpmiteration]</a>, the data
consistency term can be reintroduced into the DDPM model.</p>
<p>Choi et al. guide the diffusion process by trying to match the low
frequency content of a target image to the low frequency content of the
prediction <span class="math notranslate nohighlight">\(\argmin_x \phi(s) - phi(x)\)</span>. They do this by using a
very simple linear data consistency function, corresponding to a
difference between linear low-pass filtered representations, which they
call ILVR (iterative latent variable refinement)</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \label{eq:ilvr}
    x_{t-1} &amp; = \phi(s_{t}) + (I - \phi) (x_{t})  \\
    x_{t-1} &amp; = x_{t} + \phi(s_{t}) - \phi(x_{t}) \\
    x_{t-1} &amp; = x_{t} + \phi(s_{t} -x_{t})\end{aligned}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi\)</span> is a linear filter operation and <span class="math notranslate nohighlight">\(s_t\)</span> is
obtained by using the forward process on the target
image. <a href="#id35"><span class="problematic" id="id36">:raw-latex:`\autocite{choi2021ilvr}`</span></a></p>
<p>Similarly, Lugmayr et al. use a conditioning on known parts of the image
for the inpainting operation, which effectively boils down to applying a
linear mask that zeroes out known parts in the prediction and replaces
them with outputs from the forward process.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \label{eq:repaint}
    % Mx_t (0 at unknown, 1 at known) removes known parts from x_t and leaves unknown
    % Ms_t (0 at unknown, 1 at known) leaves prediction in unknown region and replaces known region
    x_{t-1} &amp; = x_t - \mathcal{M}(x_t) + \mathcal{M}(s_t) \\
    x_{t-1} &amp; = x_t + \mathcal{M}(s_t - x_t)\end{aligned}\end{split}\]</div>
<p>As is easily seen, Eq. <a class="reference external" href="#eq:ilvr">[eq:ilvr]</a> and
Eq. <a class="reference external" href="#eq:repaint">[eq:repaint]</a> take the same form and can be
interpretated as simultaneously taking gradient ascent steps for
optimizing <span class="math notranslate nohighlight">\(\argmax_x \log p(x)\)</span> and
<span class="math notranslate nohighlight">\(\argmax_x \log p(s|x)\)</span>.</p>
<p>Assuming distribution over latent predictions and targets at diffusion
timestep <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(p(s|t)\)</span> and <span class="math notranslate nohighlight">\(p(x|t)\)</span>, and
<span class="math notranslate nohighlight">\(\mathcal{L}\)</span> corresponding to an arbitrary linear operation</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \mathcal{L}(p(s|t) - p(x|t))                                                       &amp; = \nabla_{x_t} \log p(s_t|x_t)         \\
    \int \mathcal{L}(p(s|t) - p(x|t)) dt                                               &amp; = \int \nabla_{x_t} \log p(s_t|x_t) dt \\
    \int \mathcal{L}(p(s|t))dt - \int \mathcal{L}(p(x|t))dt                            &amp; = \log p(s|x)                          \\
    \mathcal{L} \left(\int p(s|t)dt \right) - \mathcal{L} \left( \int p(x|t)dt \right) &amp; = \log p(s|x)                          \\
    \mathcal{L}(p(s)) - \mathcal{L}(p(x))                                              &amp; = \log p(s|x)\end{aligned}\end{split}\]</div>
<p>where the left side of the equation is the original</p>
</section>
</section>
</section>
<section id="related-work">
<h1>Related Work<a class="headerlink" href="#related-work" title="Link to this heading"></a></h1>
<section id="ddpms-for-image-synthesis">
<h2>DDPMs for Image Synthesis<a class="headerlink" href="#ddpms-for-image-synthesis" title="Link to this heading"></a></h2>
</section>
<section id="image-guided-diffusion-and-reconstruction">
<h2>Image-Guided Diffusion and Reconstruction<a class="headerlink" href="#image-guided-diffusion-and-reconstruction" title="Link to this heading"></a></h2>
<p><strong>Conditioning of DDPMs on Accelerated MRI</strong>
Semester Thesis
Lionel Peer
Department of Information Technology and Electrical Engineering</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><strong>Advisors:</strong></p></td>
<td><p>Georg Brunner &amp; Emiljo Mëhillaj</p></td>
</tr>
<tr class="row-even"><td><p><strong>Supervisor:</strong></p></td>
<td><p>Prof. Dr. Ender Konukoglu</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>Computer Vision Laboratory, Group for Biomedical
Image Computing</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>Department of Information Technology and
Electrical Engineering</p></td>
</tr>
</tbody>
</table>
<p>January 10, 2020</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../_autosummary/diffusion_models.utils.mp_setup.DDP_Proc_Group.html" class="btn btn-neutral float-left" title="diffusion_models.utils.mp_setup.DDP_Proc_Group" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../idea_corner.html" class="btn btn-neutral float-right" title="Idea Corner" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Lionel Peer.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>